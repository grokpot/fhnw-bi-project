{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transform.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPo+L8kmHxLMvnLZqzjGYOM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umejTYxckBqg"
      },
      "source": [
        "# Pseudocode\n",
        "- Read in excel file\n",
        "- For each row\n",
        "    - Determine language by reading text field (https://stackoverflow.com/questions/43377265/determine-if-text-is-in-english)\n",
        "    - Clean Text\n",
        "        - Write modifications to transformation workbook\n",
        "        - Cases currently failing:\n",
        "            id=423: 6.000\n",
        "            id=687: ST ELMER'S\n",
        "            id=19,694: 1 1/2\"\n",
        "            id=502,453: not being translated, we could try using the region of the plant to improve the translation success variance\n",
        "    - If language is not english, translate to english\n",
        "        - Write translations to transformation workbook\n",
        "    - Split on spaces to create tokens\n",
        "    - For each token, write row into new workbook. Same data as before but `text` is replaced by `token` and addl column `language`\n",
        "\n",
        "# NOTE\n",
        "It's nice to use this Colab notebook for understanding, but because the code is split into chunks, the workbooks are created and if we don't run those code chunks every time, the workbooks could be stuck in memory and the data output could be old.  \n",
        "Therefore, it's recommended to ***run all code chunks CTRL+F9 every time you want to run the program***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZackixFGkXjK"
      },
      "source": [
        "# Pip Installations\n",
        "Installs libraries that aren't native to Python core"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAPQmtdkkNVP",
        "outputId": "4f15576e-56b1-4a8a-fad2-09cc8a0b0027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install langdetect\n",
        "!pip install googletrans\n",
        "!pip install openpyxl"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (1.0.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect) (1.15.0)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.6/dist-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2020.6.20)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (1.2.0)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (1.4.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.6/dist-packages (from httpx==0.13.3->googletrans) (2020.10.20)\n",
            "Requirement already satisfied: contextvars>=2.1; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from sniffio->httpx==0.13.3->googletrans) (2.4)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.6/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.6/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars>=2.1; python_version < \"3.7\"->sniffio->httpx==0.13.3->googletrans) (0.14)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.6/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.6/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.6/dist-packages (2.5.9)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.6/dist-packages (from openpyxl) (1.4.1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.6/dist-packages (from openpyxl) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNGAb1jWkmlx"
      },
      "source": [
        "# Imports\n",
        "Imports libraries (Python core and 3rd party (installed via pip)) into our runtime environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTuvJx5aiOlg"
      },
      "source": [
        "import html\n",
        "import os\n",
        "from langdetect import detect\n",
        "from googletrans import Translator\n",
        "from openpyxl import load_workbook, Workbook\n",
        "from openpyxl.utils import get_column_letter"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCwUiOeTj_MV"
      },
      "source": [
        "# Global Variables\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DuC5YpalGE8"
      },
      "source": [
        "# Constants (don't change)\n",
        "WB_SOURCE_FILENAME = \"Sample_Data.xlsx\"\n",
        "SOURCE_TEXT_COL = 5\n",
        "WB_DEST_FILENAME = \"Tokenized_Data.xlsx\"\n",
        "WB_TRANS_FILENAME = \"Text_Transformations.xlsx\"\n",
        "# Variables (do change)\n",
        "# Keeps track of which row to write to\n",
        "write_row_index = 1\n",
        "trans_row_index = 1\n",
        "# Google requires we instantiate an instance of its Translator class for use\n",
        "translator = Translator()"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wipwIuOoFrwo"
      },
      "source": [
        "Function: print_progress  \n",
        "This is just for printing the progress. Not important"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXbAQuUBF3aq"
      },
      "source": [
        "import sys\n",
        "def print_progress(num_current, num_total):\n",
        "    sys.stdout.write('\\r')\n",
        "    sys.stdout.write(f\"Processing {num_current}/{num_total}\")\n",
        "    sys.stdout.flush()"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcgwHI9vlQj6"
      },
      "source": [
        "# Function: write_transformation\n",
        "For any transformations we make with the `text` field such as translations, removing special characters, etc., we log them to a separate excel file for integrity auditing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLAJMBWBlUmp"
      },
      "source": [
        "def write_transformation(sheet_trans, row_pk, type_str, text_old, text_new, *args):\n",
        "    \"\"\"\n",
        "    Write Transformation to Tranformation Workbook\n",
        "    \"\"\"\n",
        "    global trans_row_index\n",
        "    sheet_trans.cell(row=trans_row_index, column=1).value = row_pk\n",
        "    sheet_trans.cell(row=trans_row_index, column=2).value = type_str\n",
        "    sheet_trans.cell(row=trans_row_index, column=3).value = text_old\n",
        "    sheet_trans.cell(row=trans_row_index, column=4).value = text_new\n",
        "    for i, arg in enumerate(args):\n",
        "        sheet_trans.cell(row=trans_row_index, column=5 + i).value = arg\n",
        "    trans_row_index += 1"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ye5MuOFlyG8"
      },
      "source": [
        "# Fuction: decode_html\n",
        "A text transformation function which detects HTML encodings and decodes them to unicode  \n",
        "Example: `B&uuml;rot&uuml;r` -> `Bürotür`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWIDSJ0UlwQ8"
      },
      "source": [
        "def decode_html(row_i, text, sheet_trans):\n",
        "    \"\"\"\n",
        "    Transform HTML encodings into Unicode\n",
        "    \"\"\"\n",
        "    while \"&\" in text and \";\" in text:\n",
        "        code = text[text.find(\"&\") + 1 : text.find(\";\")]\n",
        "        code_lower = code.lower()\n",
        "        if code_lower in html.entities.html5.keys():\n",
        "            text_old = text\n",
        "            text = text.replace(f\"&{code};\", html.entities.html5[code_lower])\n",
        "            write_transformation(sheet_trans, row_i, \"HTML DECODING\", text_old, text)\n",
        "        else:\n",
        "            break\n",
        "    return text"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8YMmLuRm8my"
      },
      "source": [
        "# Function: remove_special_chars\n",
        "A text transformation function which detects special characters and removes them.  \n",
        "This is largely dependent on how we want the text analysis to perform. Maybe we want commas, etc. to appear in the data for analysis, but for now, the common characters are removed.\n",
        "We could have used a library for this to simply remove everything that is not `a-z`, but by manually listing the common characters, maybe we'll find something that stands out (for example, `(R)` or `(TM)` would have been transformed to just `R` and `TM` if we used a library)\n",
        "\n",
        "**Known problems**\n",
        "- Using \" for inches (ex: #19: CROCODILE ACKAGING TAN 2\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yylz-fY3m7ld"
      },
      "source": [
        "def remove_special_chars(row_i, text, sheet_trans):\n",
        "    \"\"\"\n",
        "    Remove special characters\n",
        "    \"\"\"\n",
        "    for substr in [\n",
        "        \"(R)\",\n",
        "        \"(TM)\",\n",
        "        \"®\",\n",
        "        \"(\",\n",
        "        \")\",\n",
        "        \",\",\n",
        "        \".\",\n",
        "        \":\",\n",
        "        \";\",\n",
        "        \"[\",\n",
        "        \"]\",\n",
        "        '\"',\n",
        "        \"'\",\n",
        "        \"+\",\n",
        "        \"-\",\n",
        "        \"&\",\n",
        "    ]:\n",
        "        if substr in text:\n",
        "            text_old = text\n",
        "            text = text.replace(substr, \" \")\n",
        "            write_transformation(sheet_trans, row_i, \"SPECIAL CHAR\", text_old, text)\n",
        "    return text"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzrACf3MwEvn"
      },
      "source": [
        "# Function: translate\n",
        "Takes the text as input  \n",
        "Uses the Google langdetect to detect the language  \n",
        "If langage is not english, translates to english and records this in the text transformations excel sheet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jJSNO3Hwen_"
      },
      "source": [
        "def translate(row_i, text, sheet_trans):\n",
        "    \"\"\"\n",
        "    Detect row language and translate to English if necessary\n",
        "    \"\"\"\n",
        "    row_lang = detect(text)\n",
        "    text_temp = text\n",
        "    if row_lang != \"en\":\n",
        "        text = translator.translate(text).text\n",
        "        write_transformation(\n",
        "            sheet_trans,\n",
        "            row_i,\n",
        "            \"TRANSLATION\",\n",
        "            text_temp,\n",
        "            text,\n",
        "            row_lang,\n",
        "        )\n",
        "    return text"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjV2v2R8oaXz"
      },
      "source": [
        "# Function: get_tokens\n",
        "Takes the text as input and splits it based on spaces to produce a list of tokens.  \n",
        "Discards tokens with more than one character because not much value was found from single character tokens.  \n",
        "For example: `a quick brown fox` -> `['quick', 'brown', 'fox']`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aI_aHlTXoZrQ"
      },
      "source": [
        "def get_tokens(text):\n",
        "    split_text = text.split(\" \")\n",
        "    # Keep tokens with len > 1 (there are a lot of empty strings or single character results)\n",
        "    tokens_list = list(filter(lambda x: len(x) > 1, split_text))\n",
        "    return tokens_list"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hAsqhONpkij"
      },
      "source": [
        "# The \"Main\" Function\n",
        "In a traditional python file, the following sections would be consolidated into a single function. Instead below, we walk through each code \"chunk\" and explain it in sections\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECyhJbQjtjWy"
      },
      "source": [
        "### Opening / Creating the workbooks\n",
        "*   Open the Sample Data workbook\n",
        "  * This already exists, so we must simply open it and get the first sheet (`.active`)\n",
        "*   Create the destination workbook (\"Tokenized_Data.xlsx\")\n",
        "*   Create the text transformations workbook\n",
        "For the workbooks we're creating, we try to remove them first in order to delete old copies so if we're running this program multiple times, we don't have data overlapping. The Python operating system (`os`) throws an error if the file does not exists, which is why we include `except ... pass` which means just move on if that error is thrown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF3Qem_su21N"
      },
      "source": [
        "# Open source workbook\n",
        "wb_source = load_workbook(filename=WB_SOURCE_FILENAME)\n",
        "sheet_source = wb_source.active\n",
        "\n",
        "# Create destination workbook\n",
        "try:\n",
        "    os.remove(WB_DEST_FILENAME)\n",
        "except OSError:\n",
        "    pass\n",
        "wb_dest = Workbook()\n",
        "sheet_dest = wb_dest.active\n",
        "\n",
        "# Create transformation workbook\n",
        "try:\n",
        "    os.remove(WB_DEST_FILENAME)\n",
        "except OSError:\n",
        "    pass\n",
        "wb_trans = Workbook()\n",
        "sheet_trans = wb_trans.active"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7tE-zUNuyHf"
      },
      "source": [
        "### Iterating through the sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xuSlzeOpevU",
        "outputId": "918c3dc2-fe4c-4197-ed91-adca2a123e8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Iterate through rows\n",
        "num_rows = sheet_source.max_row\n",
        "# we need to start counting at row '2' because openpyxl starts counting at 1\n",
        "#   and also includes a row for the column numbers (metadata)\n",
        "for row_i in range(2, num_rows):\n",
        "    print_progress(row_i, num_rows - 1)\n",
        "\n",
        "    # Ignore this, saving it in case we need it later\n",
        "    #\n",
        "    # Get every column of the row and put it into a python list\n",
        "    # We use the openpyxl reference notation such as \"A0:X0\"\n",
        "    source_row_values = [\n",
        "        cell.value\n",
        "        for cell in sheet_source[\n",
        "            f\"A{row_i}\":f\"{get_column_letter(sheet_source.max_column)}{row_i}\"\n",
        "        ][0]\n",
        "    ]\n",
        "\n",
        "    text = sheet_source[f\"{get_column_letter(SOURCE_TEXT_COL + 1)}{row_i}\"].value\n",
        "    # Decode HTML characters before translation to improve translation detection\n",
        "    text = decode_html(row_i, text, sheet_trans)\n",
        "    text = translate(row_i, text, sheet_trans)\n",
        "    # Remove special chars after translation, in case translator added some\n",
        "    text = remove_special_chars(row_i, text, sheet_trans)\n",
        "    # Make everything lowercase to improve analysis\n",
        "    text = text.lower()\n",
        "\n",
        "    tokens = get_tokens(text)\n",
        "    # Write tokenized rows to dest workbook\n",
        "    for token in tokens:\n",
        "        # Written row will be: [row index, token, row_lang]\n",
        "        dest_row_values = [row_i, token, row_lang]\n",
        "        # openpyxl doesn't have a writerow() function so here's a nice O(n^3) loop\n",
        "        for val_i, val in enumerate(dest_row_values):\n",
        "            sheet_dest.cell(row=write_row_index, column=val_i + 1).value = val\n",
        "\n",
        "        write_row_index += 1\n",
        "\n"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing 1000/1000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11mLNmrBuLO9"
      },
      "source": [
        "### Saving the workbooks\n",
        "So far, all the cell manipulations we've done (putting data into excel cells) has been in memory and not written to a file. Here we save the files to the filesystem.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vIAig8uuSv1"
      },
      "source": [
        "# Ignore this, saving it for later\n",
        "# Since we're downloading from Google Colab, the browser caches the files by name and returns old versions,\n",
        "#   so append the current time to the filename (could have used uuid but this is more human friendly)\n",
        "# from datetime import datetime\n",
        "# now_strftime_extension = '_' + datetime.strftime(datetime.now(), '%y-%m-%d-%H-%M') + '.xlsx'\n",
        "# wb_trans.save(filename=WB_TRANS_FILENAME.replace('.xlsx', now_strftime_extension))\n",
        "# wb_dest.save(filename=WB_DEST_FILENAME.replace('.xlsx', now_strftime_extension))\n",
        "\n",
        "wb_trans.save(filename=WB_TRANS_FILENAME)\n",
        "wb_dest.save(filename=WB_DEST_FILENAME)"
      ],
      "execution_count": 171,
      "outputs": []
    }
  ]
}